"use client";

import { useEffect, useRef, useState, useCallback } from "react";
import { Button } from "@/components/ui/button";
import {
  InputGroup,
} from "@/components/ui/input-group";
import {
  Tooltip,
  TooltipContent,
  TooltipProvider,
  TooltipTrigger,
} from "@/components/ui/tooltip";
import { Mic, MicOff, SendHorizontalIcon, X, Loader2 } from "lucide-react";
import TextareaAutosize from "react-textarea-autosize";

interface Props {
  /** TextBox ã‚’é–‰ã˜ã‚‹ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯ */
  onClose: () => void;
  /** é€ä¿¡ãƒœã‚¿ãƒ³ã‚’æŠ¼ã—ãŸã¨ãã®ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼ˆèªè­˜ãƒ†ã‚­ã‚¹ãƒˆã‚’æ¸¡ã™ï¼‰ */
  onSubmit: (text: string) => void;
}

type RecordingState = "idle" | "recording" | "processing";

export default function TextBox({ onClose, onSubmit }: Props) {
  const [isMounted, setIsMounted] = useState(false);
  const [recordingState, setRecordingState] = useState<RecordingState>("idle");
  const [transcript, setTranscript] = useState("");
  const [error, setError] = useState("");

  const mediaRecorderRef = useRef<MediaRecorder | null>(null);
  const audioChunksRef = useRef<Blob[]>([]);
  const streamRef = useRef<MediaStream | null>(null);

  useEffect(() => {
    setIsMounted(true);
  }, []);

  // ãƒã‚¦ãƒ³ãƒˆå¾Œã«è‡ªå‹•éŒ²éŸ³é–‹å§‹
  useEffect(() => {
    if (isMounted) {
      // å°‘ã—é…ã‚‰ã›ã¦UIãŒæç”»ã•ã‚Œã¦ã‹ã‚‰é–‹å§‹
      const timer = setTimeout(() => {
        startRecording();
      }, 400);
      return () => clearTimeout(timer);
    }
    // eslint-disable-next-line react-hooks/exhaustive-deps
  }, [isMounted]);

  // ã‚¢ãƒ³ãƒã‚¦ãƒ³ãƒˆæ™‚ã«ã‚¹ãƒˆãƒªãƒ¼ãƒ ã‚’è§£æ”¾
  useEffect(() => {
    return () => {
      stopStream();
    };
  }, []);

  const stopStream = () => {
    if (streamRef.current) {
      streamRef.current.getTracks().forEach((track) => track.stop());
      streamRef.current = null;
    }
  };

  /** éŒ²éŸ³é–‹å§‹ */
  const startRecording = useCallback(async () => {
    try {
      setError("");
      audioChunksRef.current = [];

      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      streamRef.current = stream;

      // WEBM_OPUSã§éŒ²éŸ³ï¼ˆroute.tsã®APIã«åˆã‚ã›ã‚‹ï¼‰
      const mimeType = MediaRecorder.isTypeSupported("audio/webm;codecs=opus")
        ? "audio/webm;codecs=opus"
        : MediaRecorder.isTypeSupported("audio/webm")
        ? "audio/webm"
        : "audio/ogg;codecs=opus";

      const mediaRecorder = new MediaRecorder(stream, { mimeType });
      mediaRecorderRef.current = mediaRecorder;

      mediaRecorder.ondataavailable = (e) => {
        if (e.data.size > 0) {
          audioChunksRef.current.push(e.data);
        }
      };

      mediaRecorder.start(100); // 100msã”ã¨ã«ãƒ‡ãƒ¼ã‚¿ã‚’åé›†
      setRecordingState("recording");
    } catch (err: any) {
      const msgs: Record<string, string> = {
        NotAllowedError: "âŒ ãƒã‚¤ã‚¯ã®ã‚¢ã‚¯ã‚»ã‚¹ãŒæ‹’å¦ã•ã‚Œã¾ã—ãŸã€‚ãƒ–ãƒ©ã‚¦ã‚¶ã®è¨­å®šã§ãƒã‚¤ã‚¯ã‚’è¨±å¯ã—ã¦ãã ã•ã„ã€‚",
        NotFoundError: "âŒ ãƒã‚¤ã‚¯ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚æ¥ç¶šã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚",
        NotSupportedError: "âŒ ã“ã®ç’°å¢ƒã§ã¯ãƒã‚¤ã‚¯ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚",
      };
      setError(msgs[err.name] ?? `âŒ ã‚¨ãƒ©ãƒ¼: ${err.message ?? err.name}`);
      setRecordingState("idle");
    }
  }, []);

  /** éŒ²éŸ³åœæ­¢ â†’ Google Cloud Speech-to-Text APIã¸é€ä¿¡ */
  const stopRecordingAndTranscribe = useCallback(async () => {
    if (!mediaRecorderRef.current || recordingState !== "recording") return;

    setRecordingState("processing");

    // éŒ²éŸ³åœæ­¢ã—ã¦ãƒ‡ãƒ¼ã‚¿ã‚’åé›†
    await new Promise<void>((resolve) => {
      const recorder = mediaRecorderRef.current!;
      recorder.onstop = () => resolve();
      recorder.stop();
    });

    stopStream();

    try {
      const audioBlob = new Blob(audioChunksRef.current, { type: "audio/webm;codecs=opus" });

      // Blobã‚’Base64ã«å¤‰æ›
      const base64Audio = await blobToBase64(audioBlob);

      // route.ts ã¸é€ä¿¡
      const response = await fetch("/api/transcribe", {
        method: "POST",
        headers: { "Content-Type": "application/json" },
        body: JSON.stringify({ audio: base64Audio }),
      });

      const data = await response.json();

      if (!response.ok) {
        throw new Error(data.error || "éŸ³å£°èªè­˜ã«å¤±æ•—ã—ã¾ã—ãŸ");
      }

      // Google Speech APIã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‹ã‚‰æ–‡å­—èµ·ã“ã—çµæœã‚’å–å¾—
      const results = data.results as any[] | undefined;
      if (results && results.length > 0) {
        const text = results
          .map((r: any) => r.alternatives?.[0]?.transcript ?? "")
          .join("");
        setTranscript(text);
        setError("");
      } else {
        setError("âš ï¸ éŸ³å£°ãŒèªè­˜ã•ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚ã‚‚ã†ä¸€åº¦ãŠè©¦ã—ãã ã•ã„ã€‚");
      }
    } catch (err: any) {
      setError(`âŒ éŸ³å£°èªè­˜ã‚¨ãƒ©ãƒ¼: ${err.message}`);
    } finally {
      setRecordingState("idle");
    }
  }, [recordingState]);

  /** ãƒã‚¤ã‚¯ãƒœã‚¿ãƒ³ã®ãƒˆã‚°ãƒ« */
  const toggleMic = useCallback(() => {
    if (recordingState === "recording") {
      stopRecordingAndTranscribe();
    } else if (recordingState === "idle") {
      startRecording();
    }
    // processingä¸­ã¯ãƒœã‚¿ãƒ³ç„¡åŠ¹
  }, [recordingState, startRecording, stopRecordingAndTranscribe]);

  /** é–‰ã˜ã‚‹ */
  const handleClose = () => {
    if (mediaRecorderRef.current && recordingState === "recording") {
      mediaRecorderRef.current.stop();
    }
    stopStream();
    onClose();
  };

  /** é€ä¿¡ */
  const handleSubmit = () => {
    const text = transcript.trim();
    if (!text) return;
    if (mediaRecorderRef.current && recordingState === "recording") {
      mediaRecorderRef.current.stop();
    }
    stopStream();
    onSubmit(text);
  };

  if (!isMounted) return null;

  const isRecording = recordingState === "recording";
  const isProcessing = recordingState === "processing";

  return (
    <div className="fixed bottom-28 left-1/2 w-full max-w-2xl -translate-x-1/2 px-4 z-50 animate-in slide-in-from-bottom-4 duration-200">
      <TooltipProvider>
        <div className="flex flex-col gap-2">

          {/* ã‚¨ãƒ©ãƒ¼è¡¨ç¤º */}
          {error && (
            <div className="px-4 py-2 rounded-xl bg-red-50 border border-red-200 text-sm text-red-700">
              {error}
            </div>
          )}

          {/* éŒ²éŸ³ä¸­ã‚¤ãƒ³ã‚¸ã‚±ãƒ¼ã‚¿ãƒ¼ */}
          {isRecording && (
            <div className="flex items-center gap-2 px-4 py-1.5 rounded-xl bg-teal-50 border border-teal-200 text-sm text-teal-700 w-fit">
              <span className="w-2 h-2 rounded-full bg-red-500 animate-pulse" />
              éŒ²éŸ³ä¸­â€¦ ãƒã‚¤ã‚¯ãƒœã‚¿ãƒ³ã§åœæ­¢
            </div>
          )}

          {/* å‡¦ç†ä¸­ã‚¤ãƒ³ã‚¸ã‚±ãƒ¼ã‚¿ãƒ¼ */}
          {isProcessing && (
            <div className="flex items-center gap-2 px-4 py-1.5 rounded-xl bg-blue-50 border border-blue-200 text-sm text-blue-700 w-fit">
              <Loader2 className="w-4 h-4 animate-spin" />
              éŸ³å£°ã‚’èªè­˜ä¸­â€¦
            </div>
          )}

          {/* ãƒ†ã‚­ã‚¹ãƒˆãƒœãƒƒã‚¯ã‚¹æœ¬ä½“ */}
          <InputGroup className="bg-background shadow-2xl rounded-3xl border-2 overflow-hidden items-end flex pr-2">

            <TextareaAutosize
              minRows={1}
              maxRows={5}
              value={transcript}
              onChange={(e) => setTranscript(e.target.value)}
              placeholder={
                isRecording
                  ? "ğŸ¤ éŒ²éŸ³ä¸­â€¦ ãƒã‚¤ã‚¯ãƒœã‚¿ãƒ³ã‚’æŠ¼ã—ã¦åœæ­¢"
                  : isProcessing
                  ? "â³ éŸ³å£°ã‚’èªè­˜ä¸­â€¦"
                  : "éŸ³å£°å…¥åŠ›ã¾ãŸã¯ç›´æ¥å…¥åŠ›ã—ã¦ãã ã•ã„"
              }
              className="flex-1 !text-base border-none focus:ring-0 resize-none py-4 px-4 bg-transparent outline-none leading-tight"
              onKeyDown={(e) => {
                if (e.key === "Enter" && !e.shiftKey) {
                  e.preventDefault();
                  handleSubmit();
                }
              }}
            />

            {/* å³å´ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ */}
            <div className="flex items-center gap-1 mb-2">

              {/* ãƒã‚¤ã‚¯ ON/OFF ãƒœã‚¿ãƒ³ */}
              <Tooltip>
                <TooltipTrigger asChild>
                  <button
                    onClick={toggleMic}
                    disabled={isProcessing}
                    className={`p-2 rounded-full transition-colors ${
                      isRecording
                        ? "bg-red-100 text-red-600 hover:bg-red-200"
                        : isProcessing
                        ? "bg-blue-100 text-blue-600 cursor-wait"
                        : "hover:bg-accent text-muted-foreground hover:text-foreground"
                    } disabled:opacity-40 disabled:cursor-not-allowed`}
                  >
                    {isProcessing ? (
                      <Loader2 className="h-5 w-5 animate-spin" />
                    ) : isRecording ? (
                      <MicOff className="h-5 w-5" />
                    ) : (
                      <Mic className="h-5 w-5" />
                    )}
                  </button>
                </TooltipTrigger>
                <TooltipContent>
                  {isProcessing ? "èªè­˜ä¸­â€¦" : isRecording ? "éŒ²éŸ³åœæ­¢ï¼ˆAPIã¸é€ä¿¡ï¼‰" : "éŒ²éŸ³é–‹å§‹"}
                </TooltipContent>
              </Tooltip>

              {/* é€ä¿¡ãƒœã‚¿ãƒ³ */}
              <Tooltip>
                <TooltipTrigger asChild>
                  <Button
                    size="icon"
                    onClick={handleSubmit}
                    disabled={!transcript.trim() || isProcessing}
                    className="h-10 w-10 shrink-0 rounded-full bg-teal-500 hover:bg-teal-600 text-white disabled:opacity-40"
                  >
                    <SendHorizontalIcon className="h-5 w-5" />
                  </Button>
                </TooltipTrigger>
                <TooltipContent>äºˆå®šã¨ã—ã¦é€ä¿¡</TooltipContent>
              </Tooltip>

              {/* é–‰ã˜ã‚‹ãƒœã‚¿ãƒ³ */}
              <Tooltip>
                <TooltipTrigger asChild>
                  <button
                    onClick={handleClose}
                    className="p-2 rounded-full hover:bg-accent text-muted-foreground hover:text-foreground transition-colors"
                  >
                    <X className="h-5 w-5" />
                  </button>
                </TooltipTrigger>
                <TooltipContent>é–‰ã˜ã‚‹</TooltipContent>
              </Tooltip>

            </div>
          </InputGroup>

        </div>
      </TooltipProvider>
    </div>
  );
}

/** Blob â†’ Base64æ–‡å­—åˆ—ï¼ˆå…ˆé ­ã®data:...éƒ¨åˆ†ã‚’é™¤å»ï¼‰ */
async function blobToBase64(blob: Blob): Promise<string> {
  return new Promise((resolve, reject) => {
    const reader = new FileReader();
    reader.onloadend = () => {
      const result = reader.result as string;
      // "data:audio/webm;base64,XXXX" â†’ "XXXX" ã ã‘è¿”ã™
      const base64 = result.split(",")[1];
      resolve(base64);
    };
    reader.onerror = reject;
    reader.readAsDataURL(blob);
  });
}
